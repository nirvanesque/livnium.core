#!/usr/bin/env python3
"""
Generate Phase 3 Results Report

This script generates a comprehensive markdown report summarizing all Phase 3 results.
"""

import sys
from pathlib import Path
import numpy as np
import json
import pickle

# Add project root to path
project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def load_all_data(results_dir: Path):
    """Load all Phase 3 data and results."""
    results_dir = Path(results_dir)
    
    data = {}
    
    # Load metadata
    if (results_dir / 'metadata.json').exists():
        with open(results_dir / 'metadata.json', 'r') as f:
            data['metadata'] = json.load(f)
    
    # Load PC1 model summary
    if (results_dir / 'pc1_model_summary.json').exists():
        with open(results_dir / 'pc1_model_summary.json', 'r') as f:
            data['pc1_summary'] = json.load(f)
    
    # Load full dynamics summary
    if (results_dir / 'full_dynamics_summary.json').exists():
        with open(results_dir / 'full_dynamics_summary.json', 'r') as f:
            data['full_dynamics_summary'] = json.load(f)
    
    # Load evaluation results
    if (results_dir / 'evaluation_results.json').exists():
        with open(results_dir / 'evaluation_results.json', 'r') as f:
            data['evaluation'] = json.load(f)
    
    # Load shadow statistics
    if (results_dir / 'shadow_statistics.json').exists():
        with open(results_dir / 'shadow_statistics.json', 'r') as f:
            data['shadow_stats'] = json.load(f)
    
    return data


def generate_report(data: dict, output_file: Path):
    """Generate markdown report."""
    with open(output_file, 'w') as f:
        f.write("# Phase 3 Results: Dynamics Modeling\n\n")
        f.write("**Date**: Generated by `generate_report.py`\n\n")
        f.write("---\n\n")
        
        # Overview
        f.write("## Overview\n\n")
        f.write("Phase 3 moves from *mapping* the chaos (Phase 2) to *predicting* the chaos. ")
        f.write("We learn the \"motion law\" in the PCA space that governs how Rule 30's ")
        f.write("geometric coordinates evolve over time.\n\n")
        f.write("---\n\n")
        
        # Data Preparation
        if 'metadata' in data:
            f.write("## Data Preparation\n\n")
            metadata = data['metadata']
            f.write(f"- **Number of PCA components**: {metadata.get('n_components', 'N/A')}\n")
            f.write(f"- **Trajectory shape**: {metadata.get('trajectory_shape', 'N/A')}\n")
            f.write(f"- **PCA shape**: {metadata.get('pca_shape', 'N/A')}\n")
            f.write(f"- **Data source**: {metadata.get('data_source', 'N/A')}\n\n")
            
            if 'explained_variance' in metadata:
                f.write("### Explained Variance\n\n")
                for i, var in enumerate(metadata['explained_variance'], 1):
                    f.write(f"- PC{i}: {var:.4f} ({var*100:.2f}%)\n")
                f.write("\n")
            
            if 'correlations' in metadata:
                f.write("### Correlation with Center Column\n\n")
                for i, corr in enumerate(metadata['correlations'], 1):
                    f.write(f"- PC{i}: {corr:.4f}\n")
                f.write("\n")
            
            f.write("---\n\n")
        
        # PC1 Dynamics
        if 'pc1_summary' in data:
            f.write("## PC1 Dynamics Model\n\n")
            summary = data['pc1_summary']
            
            f.write(f"**Best Model**: {summary.get('best_model', 'N/A')}\n")
            f.write(f"**Best R²**: {summary.get('best_r2', 'N/A'):.4f}\n")
            f.write(f"**Features**: {summary.get('features', 'N/A')}\n\n")
            
            f.write("### Model Performance\n\n")
            f.write("| Model | Val R² | Test R² | Test MSE | Test MAE |\n")
            f.write("|-------|--------|---------|----------|----------|\n")
            
            for name, model_data in summary.get('models', {}).items():
                val_r2 = model_data.get('val_r2', 'N/A')
                test_r2 = model_data.get('test_r2', 'N/A')
                test_mse = model_data.get('test_mse', 'N/A')
                test_mae = model_data.get('test_mae', 'N/A')
                
                if isinstance(val_r2, (int, float)):
                    val_r2 = f"{val_r2:.4f}"
                if isinstance(test_r2, (int, float)):
                    test_r2 = f"{test_r2:.4f}"
                if isinstance(test_mse, (int, float)):
                    test_mse = f"{test_mse:.6f}"
                if isinstance(test_mae, (int, float)):
                    test_mae = f"{test_mae:.6f}"
                
                f.write(f"| {name} | {val_r2} | {test_r2} | {test_mse} | {test_mae} |\n")
            
            f.write("\n---\n\n")
        
        # Full Dynamics
        if 'full_dynamics_summary' in data:
            f.write("## Full Dynamics Model\n\n")
            summary = data['full_dynamics_summary']
            
            f.write(f"**Best Model**: {summary.get('best_model', 'N/A')}\n")
            f.write(f"**Best R²**: {summary.get('best_r2', 'N/A'):.4f}\n")
            f.write(f"**Number of components**: {summary.get('n_components', 'N/A')}\n\n")
            
            f.write("### Model Performance\n\n")
            f.write("| Model | Val R² | Test R² | Test MSE | Test MAE |\n")
            f.write("|-------|--------|---------|----------|----------|\n")
            
            for name, model_data in summary.get('models', {}).items():
                val_r2 = model_data.get('val_r2', 'N/A')
                test_r2 = model_data.get('test_r2', 'N/A')
                test_mse = model_data.get('test_mse', 'N/A')
                test_mae = model_data.get('test_mae', 'N/A')
                
                if isinstance(val_r2, (int, float)):
                    val_r2 = f"{val_r2:.4f}"
                if isinstance(test_r2, (int, float)):
                    test_r2 = f"{test_r2:.4f}"
                if isinstance(test_mse, (int, float)):
                    test_mse = f"{test_mse:.6f}"
                if isinstance(test_mae, (int, float)):
                    test_mae = f"{test_mae:.6f}"
                
                f.write(f"| {name} | {val_r2} | {test_r2} | {test_mse} | {test_mae} |\n")
            
            # Per-component performance
            best_model_name = summary.get('best_model', None)
            if best_model_name and best_model_name in summary.get('models', {}):
                best_model_data = summary['models'][best_model_name]
                if 'test_r2_per_component' in best_model_data:
                    f.write("\n### Per-Component Performance (Best Model)\n\n")
                    f.write("| Component | Test R² | Test MAE |\n")
                    f.write("|-----------|---------|----------|\n")
                    
                    r2_per_comp = best_model_data['test_r2_per_component']
                    mae_per_comp = best_model_data.get('test_mae_per_component', [])
                    
                    for i, (r2, mae) in enumerate(zip(r2_per_comp, mae_per_comp), 1):
                        f.write(f"| PC{i} | {r2:.4f} | {mae:.6f} |\n")
            
            f.write("\n---\n\n")
        
        # Prediction Horizons
        if 'evaluation' in data and 'prediction_horizons' in data['evaluation']:
            f.write("## Prediction Horizon Analysis\n\n")
            horizons_data = data['evaluation']['prediction_horizons']
            
            f.write("| Horizon | MSE | MAE | R² | RMSE |\n")
            f.write("|---------|-----|-----|----|----|\n")
            
            for horizon in sorted(horizons_data.keys(), key=int):
                h_data = horizons_data[horizon]
                f.write(f"| {horizon} | {h_data['mse']:.6f} | {h_data['mae']:.6f} | "
                       f"{h_data['r2']:.4f} | {h_data['rmse']:.6f} |\n")
            
            f.write("\n---\n\n")
        
        # Shadow Rule 30
        if 'shadow_stats' in data:
            f.write("## Shadow Rule 30\n\n")
            stats = data['shadow_stats']
            
            f.write("The Shadow Rule 30 model operates entirely in PCA space, ")
            f.write("never touching the bitwise grid. It produces synthetic time series ")
            f.write("whose distribution matches the real center column.\n\n")
            
            f.write("### Shadow Trajectory Statistics\n\n")
            f.write(f"- **Center column mean**: {stats.get('center_mean', 'N/A'):.6f}\n")
            f.write(f"- **Center column std**: {stats.get('center_std', 'N/A'):.6f}\n")
            f.write(f"- **Center column range**: [{stats.get('center_min', 'N/A'):.6f}, "
                   f"{stats.get('center_max', 'N/A'):.6f}]\n\n")
            
            # Trajectory comparison
            if 'evaluation' in data and 'trajectory_comparison' in data['evaluation']:
                f.write("### Trajectory Comparison\n\n")
                traj_comp = data['evaluation']['trajectory_comparison']
                
                f.write(f"- **Mean trajectory distance**: {traj_comp.get('mean_trajectory_distance', 'N/A'):.6f}\n\n")
                
                if 'component_results' in traj_comp:
                    f.write("| Component | MSE | MAE | R² | Correlation |\n")
                    f.write("|-----------|-----|-----|----|----|\n")
                    
                    for comp_result in traj_comp['component_results']:
                        f.write(f"| PC{comp_result['component']} | {comp_result['mse']:.6f} | "
                               f"{comp_result['mae']:.6f} | {comp_result['r2']:.4f} | "
                               f"{comp_result['correlation']:.4f} |\n")
            
            # Center column comparison
            if 'evaluation' in data and 'center_column_comparison' in data['evaluation']:
                f.write("\n### Center Column Distribution Comparison\n\n")
                center_comp = data['evaluation']['center_column_comparison']
                
                f.write(f"- **KS statistic**: {center_comp.get('ks_statistic', 'N/A'):.6f}\n")
                f.write(f"- **KS p-value**: {center_comp.get('ks_pvalue', 'N/A'):.6f}\n")
                f.write(f"- **Distributions match**: {center_comp.get('distributions_match', 'N/A')}\n")
                f.write(f"- **Real mean**: {center_comp.get('real_mean', 'N/A'):.6f}\n")
                f.write(f"- **Shadow mean**: {center_comp.get('shadow_mean', 'N/A'):.6f}\n")
                f.write(f"- **Real std**: {center_comp.get('real_std', 'N/A'):.6f}\n")
                f.write(f"- **Shadow std**: {center_comp.get('shadow_std', 'N/A'):.6f}\n")
            
            f.write("\n---\n\n")
        
        # Conclusions
        f.write("## Conclusions\n\n")
        f.write("Phase 3 demonstrates that:\n\n")
        f.write("1. **Predictability**: The PCA dynamics of Rule 30 are partially predictable. ")
        f.write("PC1 can be predicted with reasonable accuracy from PC1, PC2, PC3.\n\n")
        f.write("2. **Reducibility**: The chaotic observable of Rule 30 is reducible when ")
        f.write("viewed through geometric coordinates. The Shadow Rule 30 model operates ")
        f.write("entirely in PCA space and produces trajectories that resemble the real system.\n\n")
        f.write("3. **Interpretability**: The learned dynamics models are simple and interpretable, ")
        f.write("providing insight into how Rule 30's geometric structure evolves over time.\n\n")
        f.write("---\n\n")
        
        # Next Steps
        f.write("## Next Steps\n\n")
        f.write("- Improve center column reconstruction from PCA coordinates\n")
        f.write("- Explore symbolic regression for more interpretable dynamics\n")
        f.write("- Analyze stability properties of the learned dynamics\n")
        f.write("- Investigate long-term trajectory divergence\n")
        f.write("- Study the relationship between PCA components and physical patterns\n\n")


def main():
    """Main execution."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Generate Phase 3 results report"
    )
    
    parser.add_argument(
        '--data-dir',
        type=str,
        default='results',
        help='Directory containing Phase 3 results (default: results)'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='PHASE3_RESULTS.md',
        help='Output report file (default: PHASE3_RESULTS.md)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Print detailed output'
    )
    
    args = parser.parse_args()
    
    # Load data
    data_dir = Path(args.data_dir)
    data = load_all_data(data_dir)
    
    if args.verbose:
        print(f"Loaded data from: {data_dir}")
        print(f"Found {len(data)} data sources")
    
    # Generate report
    output_file = Path(args.output)
    generate_report(data, output_file)
    
    if args.verbose:
        print(f"Report generated: {output_file}")


if __name__ == "__main__":
    main()

