"""
Native Chain Encoder: Letter-by-Letter Chained Omcubes (Livnium Phoneme Layer)

ARCHITECTURE:
  Letter → LetterOmcube (3x3x3 geometry)
  Word → WordChain (chained LetterOmcubes)
  Sentence → SentenceChain (chained WordChains)

This creates natural morphological similarity, better generalization, and stable memory.
"""

import sys
import os
import numpy as np
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass

# Add project root to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from core.classical.livnium_core_system import LivniumCoreSystem
from core.quantum.quantum_cell import QuantumCell
from core.config import LivniumCoreConfig


# ============================================================================
# GLOBAL LEXICON (Letter-Level Memory)
# ============================================================================
class GlobalLexicon:
    """
    Persistent storage for Letter Geometries and Quantum States.
    Stores at letter-level for shared learning across words.
    """
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GlobalLexicon, cls).__new__(cls)
            cls._instance.letter_store = {}  # Maps letter -> (weights, amplitudes)
        return cls._instance
    
    def get_state(self, letter: str) -> Optional[Tuple[np.ndarray, np.ndarray]]:
        """Retrieve learned state for a letter."""
        return self.letter_store.get(letter.lower())
    
    def update_state(self, letter: str, weights: np.ndarray, amplitudes: np.ndarray):
        """Save learned state for a letter."""
        self.letter_store[letter.lower()] = (weights.copy(), amplitudes.copy())

    def clear(self):
        """Clear all stored states (for clean start)."""
        self.letter_store = {}


# ============================================================================
# CORE LOGIC: Letter-Level Geometry
# ============================================================================

def letter_to_lattice(letter: str, lattice_size: int = 3) -> LivniumCoreSystem:
    """
    Convert a single letter to a native lattice geometry.
    
    This is the atomic unit - each letter gets its own 3x3x3 geometry.
    """
    config = LivniumCoreConfig(
        lattice_size=lattice_size,
        enable_quantum=False,
        enable_symbolic_weight=True,
        enable_face_exposure=True,
    )
    
    geometry = LivniumCoreSystem(config)
    
    # Check Global Lexicon first!
    lexicon = GlobalLexicon()
    stored_data = lexicon.get_state(letter)
    
    if stored_data:
        # LOAD FROM MEMORY (Learned State)
        weights, _ = stored_data
        geometry.weights = weights.copy()
        
        # Hydrate cells for compatibility
        boundary = (lattice_size - 1) // 2
        for x in range(-boundary, boundary + 1):
            for y in range(-boundary, boundary + 1):
                for z in range(-boundary, boundary + 1):
                    idx_x, idx_y, idx_z = x + boundary, y + boundary, z + boundary
                    cell = geometry.get_cell((x, y, z))
                    if cell:
                        cell.symbolic_weight = weights[idx_x, idx_y, idx_z]
                        cell.symbol = letter
    else:
        # CREATE FROM HASH (Factory Default)
        letter_hash = hash(letter.lower()) % (2**32)
        np.random.seed(letter_hash)
        
        boundary = (lattice_size - 1) // 2
        for x in range(-boundary, boundary + 1):
            for y in range(-boundary, boundary + 1):
                for z in range(-boundary, boundary + 1):
                    coords = (x, y, z)
                    cell = geometry.get_cell(coords)
                    if cell:
                        position_hash = hash((x, y, z)) % (2**16)
                        combined_hash = (letter_hash + position_hash) % (2**32)
                        np.random.seed(combined_hash)
                        
                        # Zero-Centered Weights (-10.0 to 10.0)
                        # Allows dot products to be 0 (orthogonal) or negative (opposing)
                        cell.symbolic_weight = np.random.uniform(-10.0, 10.0)
                        cell.face_exposure = np.random.uniform(0.0, 3.0)
                        cell.symbol = letter
        
        # Init weights matrix
        weights = np.zeros((lattice_size, lattice_size, lattice_size))
        for x in range(-boundary, boundary + 1):
            for y in range(-boundary, boundary + 1):
                for z in range(-boundary, boundary + 1):
                    cell = geometry.get_cell((x, y, z))
                    if cell:
                        idx_x, idx_y, idx_z = x + boundary, y + boundary, z + boundary
                        weights[idx_x, idx_y, idx_z] = cell.symbolic_weight
        geometry.weights = weights
    
    return geometry


# ============================================================================
# LAYER 1: LetterOmcube
# ============================================================================

class LetterOmcube:
    """
    A single letter encapsulated in an Omcube geometry.
    
    This is the atomic unit - the "phoneme" of Livnium.
    """
    
    def __init__(self, letter: str, lattice_size: int = 3):
        self.letter = letter.lower()
        self.lattice_size = lattice_size
        
        # 1. Create/Load Geometry
        self.geometry = letter_to_lattice(letter, lattice_size)
        
        # 2. Create/Load Quantum State
        lexicon = GlobalLexicon()
        stored_data = lexicon.get_state(letter)
        
        if stored_data:
            _, amplitudes = stored_data
            self.quantum_state = QuantumCell(
                coordinates=(0, 0, 0),
                amplitudes=amplitudes.copy(),
                num_levels=3
            )
        else:
            # Default neutral state
            self.quantum_state = QuantumCell(
                coordinates=(0, 0, 0),
                amplitudes=np.array([1.0, 0.0, 0.0], dtype=complex), 
                num_levels=3
            )
    
    def save_state(self):
        """Commit current state to Global Lexicon."""
        lexicon = GlobalLexicon()
        lexicon.update_state(
            self.letter, 
            self.geometry.weights, 
            self.quantum_state.amplitudes
        )
    
    def get_mass(self) -> float:
        """Get the mass (total ABSOLUTE symbolic weight) of this letter."""
        if hasattr(self.geometry, 'weights'):
            return float(np.sum(np.abs(self.geometry.weights)))
        return 0.0


# ============================================================================
# LAYER 2: WordChain
# ============================================================================

class WordChain:
    """
    A word represented as a chain of entangled LetterOmcubes.
    
    Example: "run" → [r_cube, u_cube, n_cube] (entangled)
    """
    
    def __init__(self, word: str, lattice_size: int = 3):
        self.word = word.lower()
        self.letters = list(word.lower())  # Split into letters
        self.lattice_size = lattice_size
        
        # Create LetterOmcubes for each letter
        self.letter_cubes: List[LetterOmcube] = [
            LetterOmcube(letter, lattice_size) for letter in self.letters
        ]
        
        # Entangle letters in sequence
        self._entangle_letters()
    
    def _entangle_letters(self):
        """
        Physically link letters using mass-driven entanglement.
        
        This creates the emergent word geometry from letter chains.
        """
        for i in range(len(self.letter_cubes) - 1):
            prev = self.letter_cubes[i]
            next_letter = self.letter_cubes[i + 1]
            
            # Mass-driven entanglement (same logic as before)
            mass_factor = prev.get_mass() / (27.0 * self.lattice_size**3)
            amplification = 1.0 + mass_factor * 0.1
            
            # Modify next letter's quantum state
            next_letter.quantum_state.amplitudes *= amplification
            next_letter.quantum_state.normalize()
    
    def commit_learning(self):
        """Save the state of all letters in the word to long-term memory."""
        for cube in self.letter_cubes:
            cube.save_state()
    
    def get_mass(self) -> float:
        """Get total mass of the word (sum of all letter masses)."""
        return sum(cube.get_mass() for cube in self.letter_cubes)
    
    def get_geometry_vector(self) -> np.ndarray:
        """
        Get a combined geometry vector for the word.
        
        This aggregates all letter geometries into a single vector.
        Used for word-level comparison.
        """
        if not self.letter_cubes:
            return np.zeros(27)  # 3x3x3 = 27
        
        # Sum all letter weight matrices
        combined_weights = np.zeros((self.lattice_size, self.lattice_size, self.lattice_size))
        for cube in self.letter_cubes:
            if hasattr(cube.geometry, 'weights'):
                combined_weights += cube.geometry.weights
        
        # Flatten to vector
        return combined_weights.flatten()
    
    def get_quantum_vector(self) -> np.ndarray:
        """Get combined quantum state vector for the word."""
        if not self.letter_cubes:
            return np.array([1.0, 0.0, 0.0], dtype=complex)
        
        # Average quantum amplitudes across letters
        combined_amplitudes = np.zeros(3, dtype=complex)
        for cube in self.letter_cubes:
            combined_amplitudes += cube.quantum_state.amplitudes
        
        combined_amplitudes /= len(self.letter_cubes)
        return combined_amplitudes


# ============================================================================
# LAYER 3: SentenceChain (Replaces Omchain)
# ============================================================================

class SentenceChain:
    """
    A sentence represented as a chain of WordChains.
    
    This is the top-level structure that replaces the old Omchain.
    """
    
    def __init__(self, sentence: str, lattice_size: int = 3):
        self.sentence = sentence.lower()
        self.tokens = sentence.lower().split()
        self.lattice_size = lattice_size
        
        # Create WordChains for each word
        self.word_chains: List[WordChain] = [
            WordChain(word, lattice_size) for word in self.tokens
        ]
    
    def commit_learning(self):
        """Save the state of all words (and their letters) to long-term memory."""
        for word_chain in self.word_chains:
            word_chain.commit_learning()
    
    def compare(self, other_chain: 'SentenceChain', use_sequence: bool = False) -> float:
        """
        Compare two SentenceChains using sliding window resonance.
        
        This compares word-chains, which internally compare letter-chains.
        """
        total_resonance = 0.0
        matches = 0
        
        # Calculate overall word overlap for semantic distance check
        p_words = set(self.tokens)
        h_words = set(other_chain.tokens)
        overall_overlap = len(p_words & h_words) / max(len(p_words | h_words), 1) if (p_words | h_words) else 0.0
        
        # Compare each word in hypothesis against all words in premise
        for h_idx, h_word_chain in enumerate(other_chain.word_chains):
            best_match = 0.0
            
            for p_idx, p_word_chain in enumerate(self.word_chains):
                # Get combined geometry vectors for both words
                p_geo_vec = p_word_chain.get_geometry_vector()
                h_geo_vec = h_word_chain.get_geometry_vector()
                
                # Geometric Similarity (cosine similarity)
                dot_prod = np.dot(p_geo_vec, h_geo_vec)
                norm_p = np.linalg.norm(p_geo_vec)
                norm_h = np.linalg.norm(h_geo_vec)
                
                if norm_p > 0 and norm_h > 0:
                    geo_sim = dot_prod / (norm_p * norm_h)
                else:
                    geo_sim = 0.0
                
                # Quantum Interference (from combined quantum vectors)
                p_q_vec = p_word_chain.get_quantum_vector()
                h_q_vec = h_word_chain.get_quantum_vector()
                q_sim = np.real(np.vdot(p_q_vec, h_q_vec))
                
                # Word Match (exact string match)
                word_match = 1.0 if p_word_chain.word == h_word_chain.word else 0.0
                
                # Letter Overlap (morphological similarity)
                p_letters = set(p_word_chain.letters)
                h_letters = set(h_word_chain.letters)
                letter_overlap = len(p_letters & h_letters) / max(len(p_letters | h_letters), 1) if (p_letters | h_letters) else 0.0
                
                # Sequence Position
                position_sim = 1.0
                if use_sequence and len(self.word_chains) > 1 and len(other_chain.word_chains) > 1:
                    p_pos = p_idx / (len(self.word_chains) - 1)
                    h_pos = h_idx / (len(other_chain.word_chains) - 1)
                    position_sim = 1.0 - abs(p_pos - h_pos)
                
                # Combined Score
                # Weighted combination: geometry (primary), quantum, word match, letter overlap, position
                base_match_score = (
                    geo_sim * 0.4 +           # Geometric similarity (primary)
                    q_sim * 0.2 +              # Quantum interference
                    word_match * 0.15 +        # Exact word match
                    letter_overlap * 0.15 +     # Morphological similarity (NEW!)
                    position_sim * 0.1         # Position similarity
                )
                
                # Calculate semantic distance for unrelated pairs
                is_unrelated = (word_match == 0.0 and abs(geo_sim) < 0.3 and overall_overlap < 0.3 and letter_overlap < 0.2)
                
                if geo_sim < 0.0:
                    # Negative geometric = opposition - boost for contradiction
                    match_score = (geo_sim * 0.5 + q_sim * 0.2 + word_match * 0.1 + letter_overlap * 0.1 + position_sim * 0.05)
                elif is_unrelated:
                    # Unrelated topics - apply penalty
                    match_score = base_match_score * 0.5
                else:
                    # Normal case
                    match_score = base_match_score
                
                # Allow negative matches (Geometric Opposition)
                if abs(match_score) > abs(best_match):
                    best_match = match_score
            
            total_resonance += best_match
            matches += 1
        
        return total_resonance / max(1, matches)


# ============================================================================
# BACKWARD COMPATIBILITY: Keep old names for existing code
# ============================================================================

# Alias for backward compatibility
Omchain = SentenceChain
WordOmcube = WordChain  # Old code expects WordOmcube, but now it's WordChain

# Keep old function name for compatibility
def text_to_lattice_native_v2(word: str, lattice_size: int = 3) -> LivniumCoreSystem:
    """
    Backward compatibility: Create a geometry for a word.
    
    This now creates a WordChain and returns its combined geometry.
    """
    word_chain = WordChain(word, lattice_size)
    # Create a dummy geometry with combined weights
    combined_weights = word_chain.get_geometry_vector().reshape(3, 3, 3)
    
    config = LivniumCoreConfig(
        lattice_size=lattice_size,
        enable_quantum=False,
        enable_symbolic_weight=True,
        enable_face_exposure=True,
    )
    
    geometry = LivniumCoreSystem(config)
    geometry.weights = combined_weights
    
    return geometry
