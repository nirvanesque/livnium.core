# Nova v2 Architecture: Livnium Core v1.0

## Overview

**This is the frozen architecture. No more redesigns.**

The system is organized into 3 clean layers:

1. **Layer 0: Core Physics** - Pure physics engine (no tokens, no labels)
2. **Layer 1: Encoding & Heads** - Task-specific encoding and classification
3. **Layer 2: Training Scripts** - Data loading and training loops

## Layer 0: Core Physics (FROZEN)

**Location**: `nova_v2/core/`

**Files**:
- `vector_state.py` - State representation (single vector h âˆˆ â„^D)
- `physics_laws.py` - Core laws (alignment, divergence, tension)
- `vector_collapse_engine.py` - Collapse dynamics

**What it does**:
- Defines vector state `h`
- Implements OM/LO construction rules
- Computes alignment, divergence (0.38 - alignment), tension
- Evolves state through L collapse steps
- Logs trace (alignment_t, divergence_t, tension_t)

**What it does NOT know**:
- "entailment", "neutral", "contradiction"
- "tokens", "English"
- Any task-specific concepts

**Key Law**: `divergence = 0.38 - alignment`

## Layer 1: Encoding & Heads

### Text Encoding

**Location**: `nova_v2/text/`

**Files**:
- `encoder.py` - Task-agnostic text encoder

**What it does**:
- Converts tokens â†’ embeddings â†’ sentence vector
- Simple average pooling

### Task Heads

**Location**: `nova_v2/tasks/`

**SNLI Head** (`tasks/snli/`):
- `encoding_snli.py` - Builds initial state h0 from premise/hypothesis
- `head_snli.py` - Classifies h_final â†’ logits (E, N, C)

**Future Heads**:
- `tasks/dialogue/` - Dialogue encoding and generation head
- `tasks/ramsey/` - Ramsey-specific head

## Layer 2: Training Scripts

**Location**: `nova_v2/training/` and `nova_v2/chat/`

**Files**:
- `training/train_snli_vector.py` - SNLI training
- `chat/test_snli_vector.py` - SNLI testing

**What they do**:
- Load data
- Encode text â†’ initial state h0
- Run collapse â†’ h_final, trace
- Apply head â†’ logits
- Compute loss & optimize
- (Future: run watchdogs on trace)

## Data Flow

### Training Flow

```
SNLI Data
  â†“
Vocabulary Builder
  â†“
Tokenize (premise, hypothesis)
  â†“
SNLIEncoder.build_initial_state()
  â†’ h0 (initial state)
  â†’ v_p (OM vector)
  â†’ v_h (LO vector)
  â†“
VectorCollapseEngine.collapse(h0)
  â†’ h_final (collapsed state)
  â†’ trace (alignment, divergence, tension)
  â†“
SNLIHead(h_final)
  â†’ logits (E, N, C)
  â†“
CrossEntropyLoss(logits, gold_label)
  â†’ loss
  â†“
Backward & Optimize
```

### Physics Computation

```
OM (v_p) and LO (v_h) vectors
  â†“
alignment = cosine_similarity(OM, LO)
  â†“
divergence = 0.38 - alignment
  â†“
tension = |divergence|
```

## Key Principles

1. **Livnium Core = physics engine (no labels, no tasks)**
2. **Everything else = heads attached on top**
3. **Same core for SNLI, dialogue, Ramsey, etc.**
4. **Vector-based (no 3D cells, no hash collisions)**

## What Changed from nova/

### Removed
- âŒ 3D lattice with cells
- âŒ hash(token) â†’ (x, y, z)
- âŒ Token collisions (92%+)
- âŒ Direct SW per cell as signature

### Added
- âœ… Vector-based state `h`
- âœ… Tokens â†’ embeddings â†’ vectors
- âœ… Clean 3-layer architecture
- âœ… Frozen core (no more redesigns)

### Kept
- âœ… Divergence law (0.38 - alignment)
- âœ… OM/LO separation
- âœ… Collapse dynamics
- âœ… Trace logging
- âœ… Conservation-ish behavior

## Adding a New Task

To add a new task (e.g., dialogue):

1. **Create encoding** (`tasks/dialogue/encoding_dialogue.py`):
   ```python
   def build_initial_state(self, context, query):
       # Build h0 from context and query
       return h0, v_context, v_query
   ```

2. **Create head** (`tasks/dialogue/head_dialogue.py`):
   ```python
   def forward(self, h_final):
       # Output next token distribution
       return logits
   ```

3. **Create training script** (`training/train_dialogue_vector.py`):
   ```python
   # Use same VectorCollapseEngine
   # Use same physics laws
   # Just different encoding and head
   ```

**No changes to Layer 0. Ever.**

## File Structure

```
nova_v2/
â”œâ”€â”€ core/                    # Layer 0: Physics (FROZEN)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vector_state.py
â”‚   â”œâ”€â”€ physics_laws.py
â”‚   â””â”€â”€ vector_collapse_engine.py
â”œâ”€â”€ text/                    # Layer 1: Encoding
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ encoder.py
â”œâ”€â”€ tasks/                   # Layer 1: Task Heads
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ snli/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ encoding_snli.py
â”‚       â””â”€â”€ head_snli.py
â”œâ”€â”€ training/               # Layer 2: Training
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ train_snli_vector.py
â”œâ”€â”€ chat/                   # Layer 2: Testing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_snli_vector.py
â”œâ”€â”€ utils/                  # Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vocab.py
â”œâ”€â”€ data/                  # Data
â”‚   â””â”€â”€ snli/
â”‚       â”œâ”€â”€ snli_1.0_train.jsonl
â”‚       â”œâ”€â”€ snli_1.0_dev.jsonl
â”‚       â””â”€â”€ snli_1.0_test.jsonl
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md
```

## Next Steps

1. âœ… **Core is frozen** - no more redesigns
2. âœ… **Architecture is clean** - 3 layers, clear separation
3. ğŸ”„ **Tune hyperparameters** - dim, num_layers, lr, etc.
4. ğŸ”„ **Add watchdogs** - read from trace, not cells
5. ğŸ”„ **Add dialogue head** - same core, different head

## Notes

- This is the **last big conceptual rebuild**
- Next changes should be **tuning**, not **ontology changes**
- The core is **frozen** - no more redesigns
- Watchdogs can read from `trace` (alignment, divergence, tension)
- Future tasks just need new encoding + head, same core

